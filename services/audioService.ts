
export class AudioManager {
  private audioContext: AudioContext | null = null;
  private masterGain: GainNode | null = null;
  private reverbNode: ConvolverNode | null = null;
  private globalAnalyser: AnalyserNode | null = null;
  private globalSource: MediaStreamAudioSourceNode | null = null;
  
  // Stroke specific audio
  private buffers: Map<string, AudioBuffer> = new Map(); // bufferId -> AudioBuffer
  private activeSources: Map<string, { source: AudioBufferSourceNode, gain: GainNode, analyser: AnalyserNode, startTime: number }> = new Map(); // strokeId -> nodes

  public isListening: boolean = false;

  async start(): Promise<void> {
    if (this.audioContext && this.audioContext.state === 'suspended') {
      await this.audioContext.resume();
    }
    if (this.isListening) return;

    try {
      if (!this.audioContext) {
        this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        this.masterGain = this.audioContext.createGain();
        this.masterGain.connect(this.audioContext.destination);
        
        // Simple Reverb Impulse (Synthetic)
        this.reverbNode = this.audioContext.createConvolver();
        const rate = this.audioContext.sampleRate;
        const length = rate * 2; // 2 seconds
        const impulse = this.audioContext.createBuffer(2, length, rate);
        for (let channel = 0; channel < 2; channel++) {
           const channelData = impulse.getChannelData(channel);
           for (let i = 0; i < length; i++) {
              // Exponential decay noise
              channelData[i] = (Math.random() * 2 - 1) * Math.pow(1 - i / length, 4);
           }
        }
        this.reverbNode.buffer = impulse;
        this.reverbNode.connect(this.masterGain);
      }

      // Global Mic
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      this.globalAnalyser = this.audioContext.createAnalyser();
      this.globalAnalyser.fftSize = 256;
      this.globalSource = this.audioContext.createMediaStreamSource(stream);
      this.globalSource.connect(this.globalAnalyser);
      
      this.isListening = true;
    } catch (err) {
      console.error("Error accessing microphone:", err);
      this.isListening = false;
    }
  }

  // --- RECORDING ---
  async recordAudio(duration: number = 3000): Promise<AudioBuffer | null> {
    if (!this.audioContext) await this.start();
    if (!this.audioContext) return null;

    try {
       const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
       const mediaRecorder = new MediaRecorder(stream);
       const chunks: Blob[] = [];

       return new Promise((resolve) => {
          mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
          mediaRecorder.onstop = async () => {
             const blob = new Blob(chunks, { type: 'audio/webm' });
             const arrayBuffer = await blob.arrayBuffer();
             const audioBuffer = await this.audioContext!.decodeAudioData(arrayBuffer);
             resolve(audioBuffer);
          };
          mediaRecorder.start();
          setTimeout(() => mediaRecorder.stop(), duration);
       });
    } catch (e) {
      console.error("Recording failed", e);
      return null;
    }
  }

  addBuffer(id: string, buffer: AudioBuffer) {
    this.buffers.set(id, buffer);
  }

  getBuffer(id: string) {
    return this.buffers.get(id);
  }

  // --- PLAYBACK ---
  // Added physicsSpeed parameter and motionSensitivity logic
  updateStrokeSound(
    strokeId: string, 
    bufferId: string | null, 
    config: { volume: number, pitch: number, reverb: number, motionSensitivity: number }, 
    dist: number, 
    cursorSpeed: number,
    physicsSpeed: number // New: Average velocity of stroke points
  ) {
    if (!this.audioContext || !bufferId) return;
    const buffer = this.buffers.get(bufferId);
    if (!buffer) return;

    // Determine target gain based on distance (Proximity)
    const maxDist = 300;
    const proximityGain = Math.max(0, 1 - (dist / maxDist)); 
    
    // Cursor speed modulation (Whoosh effect when mouse moves fast nearby)
    const cursorSpeedGain = Math.min(1, cursorSpeed / 20); 

    // Physics speed modulation (Sound generated by the stroke moving itself)
    // If sensitivity is 0, physicsSpeed has no effect.
    // physicsSpeed is usually between 0 and 20.
    const motionGain = Math.min(2, physicsSpeed * config.motionSensitivity * 0.1);

    // Combine gains. 
    // Logic: Base Volume is scaled by Proximity. 
    // Then modulated by interactions (cursor speed) OR internal motion.
    const finalGain = config.volume * (proximityGain * 0.8 + cursorSpeedGain * 0.2 + motionGain);

    let active = this.activeSources.get(strokeId);

    // Start if not playing
    if (!active && finalGain > 0.01) {
       const source = this.audioContext.createBufferSource();
       source.buffer = buffer;
       source.loop = true;
       
       const gain = this.audioContext.createGain();
       const analyser = this.audioContext.createAnalyser();
       analyser.fftSize = 64;

       source.connect(gain);
       gain.connect(analyser);
       gain.connect(this.masterGain!);
       
       if (this.reverbNode && config.reverb > 0) {
          const reverbGain = this.audioContext.createGain();
          reverbGain.gain.value = config.reverb;
          gain.connect(reverbGain);
          reverbGain.connect(this.reverbNode);
       }

       source.start();
       
       active = { source, gain, analyser, startTime: this.audioContext.currentTime };
       this.activeSources.set(strokeId, active);
    }

    // Update Params
    if (active) {
       // Smooth volume transition
       active.gain.gain.setTargetAtTime(finalGain, this.audioContext.currentTime, 0.1);
       
       // Pitch modulation based on speed (Doppler-ish)
       // Affected by both cursor speed (if near) and internal physics speed
       const totalSpeedFactor = (cursorSpeed * 0.5 + physicsSpeed * config.motionSensitivity) * 0.01;
       const targetPitch = config.pitch * (1 + totalSpeedFactor);
       
       active.source.playbackRate.setTargetAtTime(targetPitch, this.audioContext.currentTime, 0.1);
    }
  }

  // --- ANALYSIS ---
  getGlobalAudioData(): { average: number, low: number, mid: number, high: number } {
    if (!this.globalAnalyser) return { average: 0, low: 0, mid: 0, high: 0 };
    return this.analyzeNode(this.globalAnalyser);
  }

  getStrokeAmplitude(strokeId: string): number {
    const active = this.activeSources.get(strokeId);
    if (!active) return 0;
    const data = this.analyzeNode(active.analyser);
    return data.average / 255;
  }

  private analyzeNode(analyser: AnalyserNode) {
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    analyser.getByteFrequencyData(dataArray);

    let sum = 0;
    let lowSum = 0;
    const lowBound = Math.floor(dataArray.length * 0.2);

    for (let i = 0; i < dataArray.length; i++) {
      const val = dataArray[i];
      sum += val;
      if (i < lowBound) lowSum += val;
    }

    return {
      average: sum / dataArray.length,
      low: lowSum / lowBound || 0,
      mid: 0,
      high: 0
    };
  }

  stop() {
    this.activeSources.forEach(s => s.source.stop());
    this.activeSources.clear();
    
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    this.isListening = false;
  }
}

export const audioManager = new AudioManager();
